{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train-model-script.py\n",
    "\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Dataset\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model( X_train, y_train, args.n_estimators, args.max_depth)\n",
    "\n",
    "    # evaluate model\n",
    "    eval_model(model, X_test, y_test)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(args):\n",
    "    print(\"Reading data from dataset\")\n",
    "    # ws = Workspace(subscription_id= \"dd022f57-1b53-4cf0-b379-44a3d7d57e27\",\n",
    "    # resource_group = \"ies-pi-dev-uks-rg\",\n",
    "    # workspace_name = \"ies-pi-dev-uks-ml\")\n",
    "    # dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "    # df = dataset.to_pandas_dataframe()\n",
    "    df = pd.read_csv(args)\n",
    "    df= df.iloc[:768,:10]\n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Relative Compactness', 'Surface Area', 'Wall Area', 'Roof Area',\n",
    "       'Overall Height', 'Orientation', 'Glazing Area',\n",
    "       'Glazing Area Distribution',]].values, df['Heating Load'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(X_train, y_train, n_estimators, max_depth):\n",
    "    print(\"Training model...\")\n",
    "    \n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', MaxAbsScaler()),  # Normalise data\n",
    "        ('model', RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth))  # RandomForest model\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', rmse)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "\n",
    "    # calculate R-squared\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print('R-squared: ', r2)\n",
    "    mlflow.log_metric(\"R-squared\", r2)\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data', type=str)\n",
    "    parser.add_argument(\"--n_estimators\", dest='n_estimators', type=int, default=100)\n",
    "    parser.add_argument(\"--max_depth\", dest='max_depth', type=int, default=None)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
